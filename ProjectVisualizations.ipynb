{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CASES_PATH = \"results_remote_lb\"\n",
    "\n",
    "TEST_CASES_DICT = {\n",
    "    'Baseline': '2019_04_04_161815',\n",
    "    'Default Scaling': '2019_04_04_203319',\n",
    "    'Low Threshold Scaling': '2019_04_04_233925',\n",
    "    'Aggressive Scaling': '2019_04_05_145551'\n",
    "}\n",
    "\n",
    "FILE_TYPE_AWS_METRICS = 'aws_metrics_{0}_*.csv'\n",
    "FILE_TYPE_USER_RESPONSE = 'users{1}_response_{0}.csv'\n",
    "\n",
    "SAMPLE_PERIOD_SECONDS = 30\n",
    "\n",
    "def read_file(test_case_name, file_type, *args):\n",
    "    file_name = file_type.format(*args)\n",
    "    file_search_path = os.path.join(TEST_CASES_PATH, TEST_CASES_DICT[test_case_name], file_name)\n",
    "    file_paths = glob.glob(file_search_path)\n",
    "    \n",
    "    # Get test file with test params if not searching aws metrics\n",
    "    if file_type != FILE_TYPE_AWS_METRICS:\n",
    "        s_file_name = FILE_TYPE_AWS_METRICS.format(args[0])\n",
    "        s_file_search_path = os.path.join(TEST_CASES_PATH, TEST_CASES_DICT[test_case_name], s_file_name)\n",
    "        s_file_paths = glob.glob(s_file_search_path)\n",
    "        info_file = s_file_paths[0]\n",
    "    else:\n",
    "        info_file = file_paths[0]\n",
    "        \n",
    "    params_list = os.path.basename(info_file)[12:].split('_')\n",
    "    \n",
    "    params_dict = {\n",
    "        'start_time_seconds': int(params_list[1]),\n",
    "        'end_time_seconds': int(params_list[2])\n",
    "    }\n",
    "\n",
    "    return pd.read_csv(file_paths[0]), params_dict\n",
    "\n",
    "def get_aws_metrics_for_test_case(test_case_name):\n",
    "    aws_metrics_list = [read_file(test_case_name, FILE_TYPE_AWS_METRICS, i) for i in range(3)]\n",
    "    aws_metrics_list_pivoted = [aws_metrics[0].pivot_table('cpu0_util', ['timepoint'], 'instance_id')\n",
    "                                for aws_metrics in aws_metrics_list]\n",
    "    return aws_metrics_list_pivoted\n",
    "\n",
    "def get_user_responses_for_test_case(test_case_name, user='A'):\n",
    "    user_responses_list = []\n",
    "    for i in range(3):\n",
    "        df, params_dict = read_file(test_case_name, FILE_TYPE_USER_RESPONSE, i, user)\n",
    "        df.loc[:,'timepoint'] = (df.loc[:,'timeStamp'] / 1000) - params_dict['start_time_seconds']\n",
    "        user_responses_list.append(df)\n",
    "    return user_responses_list\n",
    "\n",
    "def plot_cpu0_util_for_test_case(test_case_name, case_num='all', show='all'):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.xlabel('Minutes')\n",
    "    plt.ylabel('CPU Utilization')\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    aws_metrics_list_pivoted = get_aws_metrics_for_test_case(test_case_name)\n",
    "    if show != 'avg' and case_num == 'all':\n",
    "        for i in range(3):\n",
    "            aws_metrics = aws_metrics_list_pivoted[i]\n",
    "            x = np.arange(0, len(aws_metrics) * SAMPLE_PERIOD_SECONDS / 60, SAMPLE_PERIOD_SECONDS / 60)\n",
    "            plt.plot(x, aws_metrics)\n",
    "    if show != 'each' or case_num != 'all':\n",
    "        if show != 'each':\n",
    "            df_concat = pd.concat(aws_metrics_list_pivoted)\n",
    "            by_row_index = df_concat.groupby(df_concat.index)\n",
    "            df_means = by_row_index.mean()\n",
    "            aws_metrics = df_means.apply(lambda row: row[row!=0].dropna().mean(), axis=1)\n",
    "        else:\n",
    "            aws_metrics = aws_metrics_list_pivoted[case_num]\n",
    "            \n",
    "        x = np.arange(0, len(aws_metrics) * SAMPLE_PERIOD_SECONDS / 60, SAMPLE_PERIOD_SECONDS / 60)\n",
    "        lines = plt.plot(x, aws_metrics)\n",
    "        lines[0].set_dashes([2, 2, 10, 2])\n",
    "\n",
    "def plot_user_response_time_for_test_case(test_case_name, case_num='all', user='A', avg=False):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Response Time')\n",
    "    plt.ylim(0, 50000)\n",
    "    \n",
    "    user_responses_list = get_user_responses_for_test_case(test_case_name, user)\n",
    "    if case_num == 'all':\n",
    "        shared_min = min([df.loc[:,'timepoint'].min() for df in user_responses_list])\n",
    "        shared_max = max([df.loc[:,'timepoint'].max() for df in user_responses_list])\n",
    "\n",
    "        bins = np.linspace(shared_min, shared_max, num=50)\n",
    "        for df in user_responses_list:\n",
    "            df['binnedTimepoint'] = pd.cut(df['timepoint'], bins)\n",
    "            binned_df = df.groupby('binnedTimepoint').mean()\n",
    "            plt.plot(binned_df.loc[:,'elapsed'].values)\n",
    "    else:\n",
    "        df = user_responses_list[case_num]\n",
    "        bins = np.linspace(df.loc[:,'timepoint'].min(), df.loc[:,'timepoint'].max(), num=50)\n",
    "        df['binnedTimepoint'] = pd.cut(df['timepoint'], bins)\n",
    "        binned_df = df.groupby('binnedTimepoint').mean()\n",
    "        plt.plot(binned_df.loc[:,'elapsed'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cpu0_util_for_test_case('Baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cpu0_util_for_test_case('Default Scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cpu0_util_for_test_case('Low Threshold Scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cpu0_util_for_test_case('Aggressive Scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_user_response_time_for_test_case('Baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_user_response_time_for_test_case('Default Scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_user_response_time_for_test_case('Low Threshold Scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_user_response_time_for_test_case('Aggressive Scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
